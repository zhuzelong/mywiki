= 2016 Q1 = 
 
---- 
2016-1-4 to 2016-1-8 
 
本周工作: 
 
- 语言识别方法及工具调研：已完成，根据项目当前需求，使用langid库即可 100% 
- NER方法及特征调研：已完成，查阅文献找到常用的NER模型及模型的比较、常用的NER特征 100% 
- NER训练数据调研：未完成，查询了wikidata和wiki页面存档的数据，暂未从中发现可用的NER标签 40% 
- 词性标注工具学习：已完成，根据神马同学的调研结果，学习RDRPOSTagger的使用方法及该tagger使用的模型 100% 
- 词性标注工具调研：已完成，对比了Stanford NLP (Java), NLTK (Python), RDRPOSTagger (Python/Java)的印地语词性标注语料库，已排除Stanford NLP 100% 
- 分词(tokenization)方法调研：未完成，查阅文献和NLTK手册后已确定的分词方法为空格分词和正则表达式分词 50% 
 
 
下周计划： 
 
- 学习印地语的词汇结构：向印地语的运营同学学习印地语的词汇结构，用于印地语分词 
- 调研分词(tokenization)方法：继续调研分词方法，并利用NLTK工具包评估正则表达式分词的效果；确定最终的分词方案 
- 实现分词的接口：先实现分词(tokenization)，暂不加入NER的识别结果；等NER模块可用后基于NER结果进行词语分块（chunking) 
- 查找用于NER的训练数据（英语、印地语） 
- 实现离线NER的功能模块 
- 对比NLTK和RDRPOSTagger对英语、印地语的词性标注效果，如果差异较大，再尝试结合两个tagger（RDRPOSTagger可利用外部tagger） 
 
 
 
---- 
2016-1-11 to 2016-1-15 
 
本周工作 
 
- 调研分词(tokenization)方法：100%, 完成调研可用的分词工具和模型，确定使用正则表达式进行分词 
- 实现分词(tokenization)接口：90%, 完成开发分词接口，但用于分词的边界符号（如空格、标点符号）需要与印地语专家确认 
- 查找用于NER的训练数据：100%，查询论文调研使用网络数据（Wiki, WordNet）生成实体词库的方法，对比Wiki词条和WordNet的数据结构后决定使用Wiki词条 
- 实现离线NER的功能模块：50%，已实现利用Stanford NER工具训练、标注实体词的功能；下一步需要利用Wiki词条和前缀树模型生成训练数据 
- 对比NLTK和RDRPOSTagger对英语、印地语的词性标注效果: 100%，检查了NLTK的印地语语料库和词性标记结果，决定使用RDRPOSTagger 
- 实现词性标注接口：90%，修改了RDRPOSTagger的API；等待协议确定后再调整输入格式 
 
 
下周计划 
- 学习印地语的词汇结构：向印地语的运营同学学习印地语的词汇结构，用于印地语分词 
- 使用XML工具解析和抽取Wiki dump的数据，输出初始的实体词库（即没有实体标签、未过滤的词库） 
- 实现（离线）实体词库匹配建立实体词训练数据，用作NER模块的模型训练；输出小量的标记结果 
- 根据NLP服务框架调整语言识别、NER、POS模块的接口 
- 实现分词（chunking）接口，整合分词（tokenize）和NER模块的结果 
 
 
 
---- 
2016-1-18 to 2016-1-22 
 
本周工作 
 
- 使用XML工具解析和抽取Wiki dump的数据: 100%，使用词性和规则过滤词条，并与神马团队提供的词条排重后合并 
- 学习C++ 
- 学习玄亮写的在线分词接口: 70% 
 
下周计划 
 
- 参考在线分词接口实现离线分词接口, 100% 
- 建立实体词条分类标签的训练集, 20% 
- 实现离线预测实体词分类, 40% 
- 调研建立分词词库的方案, 0% 
- 优化Wiki词条的过滤, 0% 
 
 
---- 
2016-1-25 to 2016-1-29 
 
本周工作 
 
- 参考在线分词接口实现离线分词接口, 100% 
- 实现离线语言识别接口，100% 
- 根据预定义实体类别抓取Wiki词条, 100%: 该分类词条可用于生成NER训练集的输入之一 
- 优化Wiki词条的过滤, 100%：修复Wiki词条ID解析错误；新增词条的categories识别及抽取 
- 实现使用Wiki词条生成NER训练集的算法，50%，已实现及测试第一阶段（共两阶段）算法的模块，即对Wiki词条进行启发式迭代分类 
 
 
下周计划 
 
- 实现使用Wiki词条生成NER训练集的第二阶段（共两阶段）算法，即从正文中选择句子作为训练数据，计划100% 
- 使用Stanford NER工具及Wiki训练集训练离线NER模型，计划100% 
- 评估离线NER模型的PR，计划70% 
- 调研建立分词词库的方案, 计划50% 
 
 
---- 
2016-2-1 to 2016-2-6 
 
本周工作 
 
- 实现使用Wiki词条生成NER训练集的第二阶段（共两阶段）算法，即从正文中选择句子作为训练数据: 100% 
- 使用Stanford NER工具及Wiki训练集训练离线NER模型: 100% 
- 使用Stanford NER对新闻语料识别新的实体词: 100% 
- 调研建立分词词库的方案: 100% 
- 实现短语识别功能模块: 100% 
- 从新闻标题中识别短语组成评测集：100% 
- 制定实体词、短语识别的评测需求并输出评测集：100% 
 
 
下周计划 
 
 
交接内容 
- 评估离线NER工具的PR，计划100% 
- 优化离线识别新实体词模块的速度，计划100% 
- 制定评估短语识别质量的方案及测试范围，计划100% 
- 评估短语识别模块的质量，计划100% 
- 制定短语词典的更新策略，并把短语词典整合进分词模块，计划100% 
 
 
 
---- 
2016-2-15 to 2016-2-20 
 
本周工作 
 
1. 熟悉SVM和seed2word分类器的算法及流程，并排查seed2word分类器解析类目编码出错的问题, 100% 
2. 优化seed2word对电影（004001）的分类效果: 正负样本比例1:10（正样本142个），目前的最优结果为准确率80%，召回率55% 
 
 
下周计划 
 
1. 优化电影（004001）及电视剧（004003）的分类效果，达到90/50的目标值。目标进度100% 
 
 
---- 
2016-2-22 to 2016-2-27 
 
本周工作 
 
1. 优化电影004001的seed2word分类效果，自测PR达到90/55，进度100% 
2. 优化电视004003的seed2word分类效果，自测PR为80/50，进度70% 
3. 发现分词模块的badcase导致电视类目的种子词优化没有效果，已将分词badcase提交玄亮排查 
4. 使用短语识别和人工筛选的方式挖掘了电视类目的实体词并已更新至实体词库，进度100% 
5. 协助分类评测，进度100% 
 
 
 
下周计划 
 
1. 协助玄亮解决分词模块的问题，计划进度100% 
2. 使用新的分词结果优化电视类目的seed2word分类效果，PR目标值90/80，计划进度100% 
3. 使用新的分词结果优化电影类目的seed2word分类效果，PR目标值90/80，计划进度100% 
 
 
 
---- 
2016-2-29 to 2016-3-5 
 
本周工作 
 
1. 协助检查分词模块badcase，进度100% 
2. 优化电视类目的seed2word分类效果，自测PR为90/60，下一个迭代重点优化召回率 
3. 优化电影类目的seed2word分类效果，自测PR为90/43，下一个迭代优化重点为扩充电视剧实体词库提高召回率 
4. 优化汽车类目的seed2word分类效果，自测PR为90/65 
5. 检查生活类目的新闻质量，暂定不对该类目进行机器分类 
6. 优化旅游类目的seed2word分类效果，根据badcase排查的结果已确定新闻源的分类有问题，并补充旅行景点的实体词 
 
 
 
下周计划 
 
1. 协助优化时尚、人际关系两个类目的分类效果，计划PR达到90/80 
2. 优化旅游类目的seed2word分类效果，计划PR达到90/80 
3. 继续优化汽车类目的分类效果，计划PR达到90/80 
4. 协助优化实体词库的质量，计划对现有词库进行过滤和筛选 
 
 
 
---- 
2016-3-7 to 2016-3-12 
 
本周工作 
 
1. 输出并检查新闻源标注错误的badcase，进度100% 
2. 优化时尚类目的分类效果，seed2word的PR为85/50 
3. 优化旅游类目的分类效果，使用标题和正文预测的PR为65/65 
4. 评测种子源，协助准备干净的训练语料，进度100% 
5. 评测短语识别结果，短语准确率约80%；使用短语识别模块挖掘旅游景点名称以提高分类的召回率，进度50% 
6. 测试神马分类器的效果，时尚类PR为99%，16%；旅游类PR为98%，1.7% 
 
 
下周计划 
 
1. 使用短语识别模块从干净的训练语料中挖掘旅游景点名称，计划进度100% 
2. 使用干净的训练语料优化旅游类目的分类效果，目标PR为90/70 
3. 使用干净的训练语料优化时尚类目的分类效果，目标PR为90/70 
 
 
Today 
 
1. 优化015分类效果, 5h 
2. 排查分词结果包含空白字符的问题, 2h 
 
 
---- 
2016-3-14 to 2016-3-19 
 
本周工作 
 
1. 优化015时尚的分类效果: PR达到93/78，进度100% 
2. 优化020旅游的分类效果: 使用Stanford NER挖掘语料中的旅游景点，NER的准确率为80%，召回率50%。 
3. 优化013人际关系的分类效果: PR为75/20，原因是正样本的特征词与社会、娱乐类新闻高度重合；建议暂时使用种子源分类 
4. 标注英语种子源，进度100% 
 
 
 
下周计划 
 
1. 提高Stanford NER的准确率和召回率 
2. 继续优化015旅游类目的分类效果，目标PR为95/60 
3. 后半周接入英语的分类优化 
 
 
 
 
---- 
2016-3-21 to 2016-3-26 
 
本周工作 
 
1. 优化英语新闻的分类效果，各类目在测试集上的准确率/召回率如下： 
1.1 电影：96/87 
1.2 电视：96/65 
1.3 占星术：97.5/88 
1.4 汽车：96/88 
1.5 时尚：95/70 
1.6 娱乐：98/70 
1.7 旅游：未知，3月26日下班前完成优化（达到上线标准） 
 
 
下周计划 
 
1. 根据印地语、英语的评测结果，修复及优化各类目的seed2word分类器 
2. 优化Stanford NER工具的准确率 
 
 
 
---- 
2016-3-28 to 2016-4-1 
 
本周工作 
 
1. 根据印地语、英语的评测结果，修复及优化各类目的seed2word分类器：进度100% 
2. 评估Stanford NER的优化工作： 
    2.1 英语分类中，地名实体词对分类的贡献不及印地语分类中实体词的贡献大；Stanford NER开箱即用的tagger对LOCATION的识别准确率超过90%，但对旅游景点的识别准确率只有46%，需要重新训练一个TRAVEL_LOCATION的tagger。目前梓力开发的短语识别器准确率超过95%，且分类暂时不需要用到实体词的标记，因此在后续迭代中使用自动识别的短语辅助分类优化。 
    2.2 实体词对娱乐、政治类目的准召率提高明显，基于上述原因，后续迭代中使用短语识别器辅助分类优化。 
3. 试验各类目分类分数规范化对准召率的影响，确定规范化配置并重新调整预测阈值：进度100%，旅游、教育类不适合规范化，其他类目使用规范化的效果更优。 
 
 
下周计划 
 
1. 配合信息流推送平台开发，计划进度100% 
2. 根据英语分类评测结果检查分类器，计划进度100% 
3. 试验候选特征词自动迭代，即给定一个特征词候选集，以准召率为目标，自动迭代添加特征词，选出能提升分类效果的子集，计划进度50% 
 
 
 
---- 
2016-4-4 to 2016-4-8 
 
本周工作 
 
1. 了解并确定消息推送系统UPMC的部署方案（包括UCMQ及数据库部署），进度100% 
2. 根据英语分类评测结果调整分类器，进度100% 
3. 调整英语新闻的电影、电视类目优化策略，根据线上分类器的策略及新的分类配置，在只包含电影、电视的测试集上，电影的准召率为95/100，电视的准召率为100/80。 
 
 
 
下周计划 
 
1. 优化娱乐的二级类目“名人”，计划进度100% 
2. 根据评测结果优化分类器 
3. 学习推荐算法及实验流程，计划进度100% 
4. 完成UPMC部署，计划进度100% 
5. 实现UPMC创建任务界面的用户分群按用户组展示 
 
 
 
---- 
2016-4-11 to 2016-4-15 
 
本周工作 
 
1. 根据评测结结果调整旅游、时尚的s2w分类器，进度100% 
2. 部署消息推送系统，内部联调，进度100% 
 
 
下周计划 
 
1. 外部联调消息推送系统，计划进度100% 
 
 
---- 
2016-4-18 to 2016-4-22 
 
本周工作 
 
1. 部署upmc管理后台，进度100% 
2. 开发分类badcase处理页面，进度100% 
3. 协助推送系统联调，进度100% 
 
 
下周计划 
 
1. 部署分类badcase处理页面 
2. 处理分类badcase及分类优化 
 
 
---- 
2016-4-25 to 2016-4-29 
 
本周工作 
 
1. 完成分类badcase网站开发，进度100% 
2. 参与推送平台联调验收工作，进度100% 
3. 修复推送平台UPMC更新发送数时死锁的问题，等待部署到测试环境进行高并发验证，进度80% 
 
 
下周计划 
 
1. 英语及印地语二级类目优化，电影（004001）和电视剧（004003），计划进度100%；神马团队本周内提供二级类目的定义 
 
 
---- 
2016-5-3 to 2016-5-6 
 
本周工作 
 
1. 协助神马团队准备二级类目（电影、电视剧、板球、电子产品）的测试语料：进度100% 
2. 完成英语的电影、电视剧分类优化：进度100%，根据新的二级类目分类策略评估，准召率均超过95/60 
3. 在LA集群的mob655上部署UAE测试集群，完成推送平台测试环境部署：进度100% 
4. 修复架构组提出的UPMC缺陷：进度50%，4个参数类型校验的缺陷暂缓修复（由国内及国际统一推送平台修复），另外4个涉及业务的缺陷已修复 
 
 
下周计划 
 
1. 完成英语、印地语二级类目优化 
 
 
--- 
2016-5-9 to 2016-5-13 
 
本周工作 
 
1. 完成英语二级类目优化：进度100%，电影、电视剧、板球、电子产品均达到上线标准 
2. 优化印地语二级类目：进度50%，板球的准召率为100/60，电子产品的准召率为97.5/86，电影、电视剧未优化 
3. 完成推送平台测试环境部署及联调：进度100% 
4. 根据推送统计需求，修改推送平台upmc：进度100% 
 
 
下周计划 
 
1. 完成印地语电影、电视剧的分类优化 
2. 配合推送平台的后续联调工作 
 
 
---- 
2016-5-16 to 2016-5-20 
 
本周工作 
 
1. 完成印地语电影、电视剧的分类优化，进度100% 
2. 修改推送平台UPMC的协议实现，支持动态扩展的协议字段，进度100% 
3. 熟悉推送平台GCM部分、统计接口的代码及WA平台的使用，进度100% 
4. 熟悉leaf server业务逻辑及代码，进度10% 
 
 
下周计划 
 
1. 熟悉leaf server的代码，计划进度100% 
2. 推荐下发的相关工作（待计划） 
 
 
---- 
2016-5-23 to 2016-5-27 
 
本周工作 
 
1. 部署CTR AUC监控脚本，进度100% 
2. 用户画像查询系统增加version查询条件，完成自测与联调，进度100% 
3. 对接UPMC推送接口协议，进度100% 
4. 对接用户画像总表，进度50%：未完成domain name的拼接 
 
 
下周计划 
 
1. 完成用户画像总表对接 
2. 配合完成推送平台全链条的测试及监控开发 
3. 英语一级类目及二级类目的badcase修复 
 
 
---- 
2016-5-30 to 2016-6-3 
 
1. 完成用户画像总表对接 
2. 配合完成推送平台全链条的测试及监控开发 
3. 英语一级类目及二级类目的badcase修复 
 
 
Today 
 
1. 优化AUC统计脚本 
    - 抽样1万用户进行groupByDn的AUC统计, sample by ds (utdid) 
2. UPMC增加文件下载模块 
 
 
---- 
2016-6-6 to 2016-6-8 
 
本周工作 
 
1. 用户画像总表对接 
2. 测试推送后台 
3. 二级类目分类修复 
4. 完善AUC统计脚本 
 
下周计划 
 
 
---- 
2016-6-12 to 2016-6-17 
 
本周工作 
 
1. 用户画像总表对接 
2. 推送后台双通道联调 
3. 二级类目修复 
4. 修复AUC统计脚本 
5. 印度机房迁移 
 
下周计划 
 
1. 印尼语一级分类 
 
 
---- 
2016-6-20 to 2016-6-24 
 
本周工作 
 
1. 优化用户画像查询系统 
2. 解决线上分类badcase 
 
 
---- 
2016-6-27 to 2016-7-1 
 
本周工作 
 
1. 部署WA日志同步脚本 
2. 开发及测试视频新需求 
3. 修复推送后台问题 
 
Todo 
 
1. 视频新需求 
    - 增加关键词过滤，放在内容同步的环节去做 
    - 全网过滤18+，直接下线视频（不涉及开发） 
    - 热门视频随机推荐（拉取超量推荐列表，随机选择进行推荐） 
2. 画像同步脚本 
    - rsync脚本修改: 修改rsync的模块名称 
    - indinews计算脚本修改: 支持多国家计算 
 
 
---- 
2016-07-04 to 2016-07-08 
 
本周工作 
 
 
---- 
2016-07-11 to 2016-07-15 
 
---- 
2016-07-24 to 2016-07-29 
 
 
---- 
2016-08-01 to 2016-08-05 
 
Today 
 
1. 优化全网NLP的分类效果  
 
Todo 
 
1. PI分类器 
`by_gramer`是核心分类模块；`by_entity`不确定有没有用；`by_url`只对印尼语生效（人为规定pattern）；`by_international_word`只用于区分国际/国内新闻，可以暂时忽略；`factory`是汇总的入口 
2. 全网ETL：把中间件日志、铜矿数据导入到LA和印度集群的Hive，放在一张表格里面 
 
1. offline-nlp/nlp_test.sh 
2. cat_sample.sh --> sample.py 
 
